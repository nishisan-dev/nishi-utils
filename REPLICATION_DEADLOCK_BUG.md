# Bug: Deadlock de Replica√ß√£o no NGrid

**Status**: üü° Fix aplicado (teste alvo OK)  
**Severidade**: Critical  
**Teste Afetado**: `MultiQueueClusterIntegrationTest.shouldHandleMultipleQueuesIndependently()`  
**Sintoma**: Timeout de 105.8 segundos (RPC timeout de 35s √ó 3 retry attempts)

---

## Resumo Executivo

O sistema NGrid apresenta deadlock em ambientes multi-queue quando m√∫ltiplos n√≥s tentam replicar opera√ß√µes simultaneamente. O deadlock ocorre devido a **contention de locks em m√∫ltiplas camadas** durante a aplica√ß√£o de opera√ß√µes replicadas.

---

## Manifesta√ß√£o do Bug

### Teste Falhando
```bash
mvn test -Dtest=MultiQueueClusterIntegrationTest#shouldHandleMultipleQueuesIndependently
```

**Erro**:
```
TimeoutException: Request timed out requestId=... destination=seed timeout=PT35S
at DistributedQueue.offer(DistributedQueue.java:162)
```

### Topologia de Teste
- **3 n√≥s**: seed (leader), producer, consumer
- **3 queues**: orders, events, logs
- **Replication factor**: 2
- **Strict consistency**: false

### Comportamento Observado
1. Producer tenta fazer `offer()` na primeira queue (orders)
2. Opera√ß√£o envia replication request para followers
3. Sistema trava aguardando ACKs que nunca chegam
4. Timeout ap√≥s 105.8 segundos

---

## Root Cause Analysis

### Arquitetura de Locks (Multi-Layer)

O NGrid possui m√∫ltiplas camadas de locks que interagem durante replica√ß√£o:

```
Layer 1: DistributedQueue
  ‚Üì
Layer 2: QueueClusterService
  ‚îú‚îÄ clientLock
  ‚îî‚îÄ operationLock
      ‚Üì
Layer 3: ReplicationManager
  ‚îî‚îÄ sequenceBufferLock
      ‚Üì
Layer 4: NQueue (Backend)
  ‚îî‚îÄ internal ReentrantLock
```

### Fluxo do Deadlock

#### Caminho do Leader (Producer)
```java
1. DistributedQueue.offer(value)
2. ‚Üí QueueClusterService.offer(value)
3.   ‚Üí Adquire clientLock
4.   ‚Üí ReplicationManager.replicate(topic, payload)
5.     ‚Üí replicateToFollowers() // envia para seed e consumer
6.     ‚Üí checkCompletion() // verifica se quorum foi atingido
7.       ‚Üí handler.apply() // BLOQUEANTE! Tenta modificar NQueue
8.   ‚Üí waitForReplication(future) // BLOQUEIA aguardando ACKs
```

#### Caminho do Follower (Seed/Consumer)
```java
1. Transport recebe REPLICATION_REQUEST
2. ‚Üí ReplicationManager.handleReplicationRequest()
3.   ‚Üí Adquire sequenceBufferLock
4.   ‚Üí applyReplication(payload, message)
5.     ‚Üí handler.apply(opId, data) // BLOQUEANTE!
6.       ‚Üí QueueClusterService.apply()
7.         ‚Üí Tenta adquirir operationLock
8.         ‚Üí NQueue.offer() // tenta lock interno da queue
9.     ‚Üí sendAck() // ACK NUNCA √â ENVIADO se apply bloquear!
10.  ‚Üí Libera sequenceBufferLock
```

### Cen√°rio de Deadlock Circular

Quando m√∫ltiplas opera√ß√µes acontecem simultaneamente em m√∫ltiplas queues:

```
Node A (Producer):
  - Mant√©m locks da queue "orders"
  - Aguarda ACK do Node B para "orders"
  - Precisa processar replication de "events" vindo de B

Node B (Seed):
  - Mant√©m sequenceBufferLock processando "events"
  - Dentro do lock, tenta aplicar "events" (bloqueia em handler.apply)
  - Aguarda ACK do Node A para "events"
  - Precisa processar replication de "orders" vindo de A
  
DEADLOCK: A aguarda B, B aguarda A
```

---

## Causa Raiz Confirmada ‚úÖ

O deadlock/timeouts em **multi-queue** n√£o vem mais de locks em si, mas de **sequenciamento global usado com buffer por t√≥pico**:

- `ReplicationManager.replicate()` usa **`globalSequence`** (√∫nico contador para TODOS os t√≥picos).
- `handleReplicationRequest()` usa **`nextExpectedSequenceByTopic`** (contador **por t√≥pico**, iniciando em 1).
- Resultado: o primeiro evento de um t√≥pico pode chegar com `seq=3`, mas o follower espera `seq=1` para aquele t√≥pico ‚Üí **fica sempre em buffer**, **nunca aplica**, **nunca manda ACK**.
- O leader ent√£o espera ACKs que nunca chegam ‚Üí **timeout** (parece deadlock).

Exemplo real com 3 queues:
```
orders  seq=1,2
events  seq=3,4,5   <-- follower espera seq=1 para "events", nunca chega
logs    seq=6,7
```

### Evid√™ncia no c√≥digo
- Sequ√™ncia global: `ReplicationManager.replicate()` usa `globalSequence.incrementAndGet()`
- Buffer por t√≥pico: `handleReplicationRequest()` compara `seq` com `nextExpectedSequenceByTopic` (iniciado em 1 por t√≥pico)

### Impacto direto
- Qualquer cluster com **mais de um topic/queue** entra em bloqueio l√≥gico porque os followers **jamais avan√ßam** o `nextExpectedSequenceByTopic` para os t√≥picos ‚Äúpulados‚Äù.

---

## Tentativas de Corre√ß√£o

### Tentativa 1: Lock Elision no QueueClusterService ‚ùå
**Abordagem**: Liberar `clientLock` e `operationLock` ANTES de chamar `waitForReplication()`

**Resultado**: Deadlock persistiu (conforme checkpoint anterior)

**An√°lise**: Libera√ß√£o de locks no service layer n√£o resolveu porque:
- `sequenceBufferLock` no ReplicationManager ainda era mantido durante `handler.apply()`
- NQueue possui lock interno que n√£o pode ser liberado

### Tentativa 2: Async Apply com Callbacks ‚ö†Ô∏è
**Abordagem**: Executar `handler.apply()` assincronamente fora de todos os locks

**Implementa√ß√£o**:
1. ‚úÖ Mudan√ßa de executor: `SingleThreadExecutor` ‚Üí `FixedThreadPool(4)`
2. ‚úÖ Follower path async: `handleReplicationRequest()` usa callbacks
3. ‚úÖ Leader path async: `checkCompletion()` usa executor
4. ‚úÖ Buffer processing recursivo via callbacks

**C√≥digo**:
```java
// ANTES (s√≠ncrono, dentro do lock)
sequenceBufferLock.lock();
try {
    if (seq == nextExpected) {
        applyReplication(payload, message); // BLOQUEANTE!
        nextExpectedSequenceByTopic.put(topic, nextExpected + 1);
        processSequenceBuffer(topic);
    }
} finally {
    sequenceBufferLock.unlock();
}

// DEPOIS (ass√≠ncrono, com callback)
sequenceBufferLock.lock();
try {
    if (seq == nextExpected) {
        Runnable onSuccess = () -> {
            sequenceBufferLock.lock();
            try {
                // Atualiza estado AP√ìS apply bem-sucedido
                lastAppliedSequence = Math.max(lastAppliedSequence, seq);
                applied.add(opId);
                sendAck(opId, message.source());
                nextExpectedSequenceByTopic.put(topic, nextExpected + 1);
                processSequenceBuffer(topic);
            } finally {
                sequenceBufferLock.unlock();
            }
        };
        applyReplication(payload, message, onSuccess); // Retorna imediatamente
    }
} finally {
    sequenceBufferLock.unlock(); // Lock liberado ANTES do apply
}
```

**Resultado**: Deadlock **AINDA PERSISTE** (timeout em 105.8s)

**Diagn√≥stico atualizado**:
O problema n√£o era lock. Era **sequ√™ncia global x buffer por t√≥pico** causando **ACKs nunca enviados**.

---

## Novo Achado (Ap√≥s Op√ß√£o A) ‚ö†Ô∏è

Ap√≥s corrigir o sequenciamento por t√≥pico, o teste ainda falhou com **timeout de RPC** em `DistributedQueue.offer()` (request para o l√≠der).

### Causa Raiz Atual
O l√≠der **n√£o processa** o `CLIENT_REQUEST` porque:
- **As filas s√£o criadas de forma lazy**. O seed (l√≠der) n√£o chama `getQueue()` e, portanto, **n√£o registra listener** para receber comandos de queue.
- O comando **n√£o carrega o nome da fila** (ex.: `queue.offer`), ent√£o mesmo se o l√≠der tivesse v√°rias filas, ele **n√£o consegue rotear** corretamente no caso multi-queue.

Resultado: o request do producer para o seed **fica sem resposta** e expira (timeout de 35s).

### Evid√™ncia
- Timeout ocorre **antes** de qualquer ACK de replica√ß√£o (RPC pendente no `DistributedQueue.invokeLeader`).
- `DistributedQueue` s√≥ processa `CLIENT_REQUEST` se existir inst√¢ncia local registrada no transport.
- Com m√∫ltiplas filas, o comando n√£o cont√©m `queueName`, ent√£o n√£o h√° roteamento determin√≠stico.

### Corre√ß√£o Planejada
1. **Incluir o nome da fila no comando** (ex.: `queue.offer:orders`) e filtrar no listener.
2. **Eager init** das filas configuradas no `NGridNode` para garantir listener + handler no l√≠der.
3. **Aplicar reten√ß√£o TIME_BASED** das `QueueConfig` nas `NQueue.Options` para habilitar `poll` por offset.
4. **Evitar double-apply no l√≠der** com CAS (`localApplyStarted`) para n√£o duplicar registros.
5. **Compatibilidade legacy**: quando `queueDirectory` √© usado (API antiga), manter `DELETE_ON_CONSUME` para preservar sem√¢ntica destrutiva do `poll`.

---

## Pr√≥ximos Passos de Corre√ß√£o

### Op√ß√£o A: Sequ√™ncia por T√≥pico (recomendado)
Manter ordena√ß√£o **por t√≥pico** e corrigir o bug usando contador dedicado:
```java
private final Map<String, AtomicLong> sequenceByTopic = new ConcurrentHashMap<>();

long seq = sequenceByTopic
    .computeIfAbsent(topic, k -> new AtomicLong(0))
    .incrementAndGet();
```
Follower continua usando `nextExpectedSequenceByTopic` (agora consistente).

### Op√ß√£o B: Sequ√™ncia Global √önica
Se a inten√ß√£o for **ordena√ß√£o global**, remover o buffer por t√≥pico e usar um √∫nico `nextExpectedSequence` global (ou aceitar processamento fora de ordem por t√≥pico).

### Op√ß√£o C: Leader Replicar Para Si Mesmo
Ainda v√°lida como refactor, mas n√£o resolve o bug de sequ√™ncia.

```java
// Leader path
public CompletableFuture<ReplicationResult> replicate(String topic, Serializable payload) {
    UUID operationId = UUID.randomUUID();
    PendingOperation operation = new PendingOperation(operationId, topic, payload, quorum);
    pending.put(operationId, operation);
    
    // Leader N√ÉO faz ACK local, envia para si mesmo tamb√©m
    for (NodeInfo member : allMembers()) { // Inclui self!
        sendReplicationRequest(member, operation);
    }
    
    return operation.future();
}
```

### Op√ß√£o D: Two-Phase Commit
Separar replica√ß√£o em 2 fases:
1. **Prepare Phase**: Followers confirmam capacidade de aplicar
2. **Commit Phase**: Ap√≥s quorum, todos aplicam atomicamente

---

## Arquivos Modificados (Tentativa 2)

- ‚úèÔ∏è `ReplicationManager.java`:
  - Linha 70-76: Executor multi-thread
  - Linha 484-523: `applyReplication()` async com callback
  - Linha 454-484: `handleReplicationRequest()` com callback
  - Linha 553-608: `processSequenceBuffer()` recursivo
  - Linha 295-332: `checkCompletion()` async

---

## Refer√™ncias

- **Checkpoint Original**: `/home/lucas/.gemini/antigravity/brain/dcc57d3f-5932-4589-90b3-5bade3b4cb87/checkpoint.md`
- **Task Atual**: `/home/lucas/.gemini/antigravity/brain/483e8146-60d3-49b4-beb0-dcfeaab77751/task.md`
- **Knowledge Item**: `ngrid_distributed_structures/artifacts/implementation/callback_sequencing_pattern.md`

---

## Timeline

| Data | A√ß√£o | Resultado |
|------|------|-----------|
| 2026-01-18 | Tentativa lock elision em QueueClusterService | ‚ùå Falhou |
| 2026-01-18 | Implementa√ß√£o async apply com callbacks | ‚ö†Ô∏è N√£o resolveu |
| 2026-01-18 | Sequ√™ncia por t√≥pico + roteamento por queue + init eager + reten√ß√£o TIME_BASED + CAS local-apply | ‚úÖ Teste alvo passou |
| 2026-01-18 | Estado atual | üü° Fix aplicado, validar regress√µes |

---

**√öltima Atualiza√ß√£o**: 2026-01-18T00:48:32-03:00
